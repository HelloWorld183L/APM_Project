# Pro Data Scientists - Applied Predictive Modelling Project

### Team members

Leon Harper (21385662)

Thomas Newton (21365654)

Michal Jedruszczak (21440496)

# Initial set-up

## Libraries to use
```{r}
install.packages("dplyr")
install.packages("ggplot2")
```

```{r}
library(dplyr)
library(ggplot2)
```

# League of Legends Dataset analysis

## Step 1: Problem statement
League of Legends is a popular MOBA (Multiplayer online battle arena) video game with millions of users every month. Due to having this many players there is bound to be some cyberbullying/toxic players included in those millions of players, League however is especially toxic and is often ranked as one of the most toxic gaming community’s today. The current ban rate of all accounts as of September 2022 is 2.25% (Around 2,632,500 account). In a survey by ADL (Anti-Defamation League) it was found 65% of adults ages 18-45 have been harassed/bullied in League of Legends in 2021.

The objective of this project is to create a model that will be able to detect cyberbullying/toxicity. By using the League of legends dataset provided to us it will allow the model to have reference for comments deemed as bullying.

This would be a classification model that when give a comment/statement would decided whether it is bullying or not bullying, it will be able to do this by detecting certain words and phrases.

Currently most video games have an option to filter chat, however this only censors certain words/phrases. Our model will be able to detect strings of words rather than just certain ones.

ADL Survey: Hate is No Game: Harassment and Positive Social Experiences in Online Games 2021 (adl.org)

## Step 2: Importing data

## Step 2.5: Preliminary EDA
```{r}
posts_lol <- read.csv("./posts_lol.csv")
annotations_lol <- read.csv("./annotations_lol.csv")
```

**LoL Preliminary EDA**

In our League of Legends posts dataset, we are given 55 rows of 5 features: topic_id, post_number, author, html_message and timestamp. For the purposes of this project, we will ignore timestamp, as it will not be used to train our models. The additional LoL annotations dataset reveals which messages were flagged as cyberbullying, from which the only useful features are the post_number and topic_id. 

Posts in the main dataset are formatted using HTML, meaning that our model will either have to be trained to recognise patterns such as paragraph breaks or we will have to clean the data and transform it into something more appropriate.

Furthermore, as we are only using a single set of features (post_number and topic_id) from the annotations dataset, we may be able to add another column to the posts dataset -- a Boolean value representing whether or not a specific post contains cyberbullying. This will eliminate the need for the use of two separate datasets to develop our models.

Regarding the types of data we're given, topic IDs, authors and HTML messages are categorical, while post numbers are ordinal. In the annotations dataset, all values but post number are categorical.

```{r}
summary(posts_lol)
```

```{r}
summary(annotations_lol)
```

```{r}
nrow(posts_lol)
```

```{r}
posts_lol %>% select("topic_id") -> lol_topics #gets all unique lol_topics from the dataset
unique(lol_topics)
```

In the posts_lol data set we have only a single topic.

```{r}
posts_lol %>% filter(topic_id == 1030) -> lol_top1030 #selects all rows with topic 1030
count(lol_top1030)
```

```{r}
annotations_lol %>% filter(topic_id == 1030) -> lol_ann1030 #selects all rows with wow_topic 1030
count(lol_ann1030)
```

```{r}
100 * count(lol_ann1030)/count(lol_top1030)#percentage of posts marked as cyberbullying
```

For this topic, we have 55 total posts and 41 of them are marked as cyberbullying. This means that 74.54545% of the posts in this topic contain cyberbullying.


## Step 3: Cleaning the data

## Step 4: EDA

## Step 5: Feature selection

## Step 6: Predictive modelling

## Step 7: Evaluation

## Step 8: Hyperparameter tuning

# Individual contributions

# References
(Note: This should be in Harvard MMU referencing style)

Bretschneider, Uwe and Peters, Ralf, "DETECTING CYBERBULLYING IN ONLINE COMMUNITIES" (2016). Research Papers. Paper 61. http://aisel.aisnet.org/ecis2016_rp/61
