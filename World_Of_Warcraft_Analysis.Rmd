# Pro Data Scientists - Applied Predictive Modelling Project

### Team members

#### Leon Harper (21385662)

#### Thomas Newton (21365654)

#### Michal Jedruszczak (21440496)

These are the team members for the group project.

# Initial set-up

## Libraries to use
```{r}
install.packages("dplyr")
install.packages("ggplot2")
install.packages("purrr")
install.packages("stopwords")
install.packages("textstem")
install.packages("rvest")
install.packages("ROSE")
install.packages("tm")
install.packages("caret")
install.packages("kernlab")
install.packages("RSNNS")
install.packages("randomForest")
install.packages("pROC")
install.packages("tictoc")
cat("\014")
```
Run the above block to install the packages necessary to run the code in the project. "cat("\014)" is used to clear the console output for presentation purposes.

```{r}
library(dplyr)
library(ggplot2)
library(xml2)
library(purrr)
library(stringr)
library(stopwords)
library(textstem)
library(rvest)
library(ROSE)
library(tm)
library(caret)
library(kernlab)
library(RSNNS)
library(randomForest)
library(pROC)
library(tictoc)
cat("\014")
```
Run the above code block to import the required libraries.

# World of Warcraft Cyberbullying Dataset analysis

## Step 1: Problem statement
World of Warcraft is a popular MMORPG (Massively multiplayer online role-playing game) video game with millions of user every month. Due to having this many players there is bound to be some cyberbullying/toxic players included in those millions of players, World of Warcraft however is especially toxic and is often ranked as one of the most toxic gaming communityâ€™s today. In a survey by ADL (Anti-Defamation League) it was found 66% of adults ages 18-45 have been harassed/bullied in World of Warcraft in 2021.

The objective of this project is to create a model that will be able to detect cyberbullying/toxicity. By using the World of Warcraft dataset provided to us it will allow the model to have reference for comments deemed as bullying.

This would be a classification model that when give a comment/statement would decided whether it is bullying or not bullying, it will be able to do this by detecting certain words and phrases.

Currently most video games have an option to filter chat, however this only censors certain words/phrases. Our model will be able to detect strings of words rather than just certain ones.

ADL Survey: Hate is No Game: Harassment and Positive Social Experiences in Online Games 2021 (adl.org)

## Step 2: Importing data
```{r}
wow_posts_df <- read.csv("Data/posts_wow.csv")
wow_annotations_df <- read.csv("Data/annotations_wow.csv")

lol_posts_df <- read.csv("Data/posts_lol.csv")
lol_annotations_df <- read.csv("Data/annotations_lol.csv")
```
This imports the required data for the project. The data was exported from an SQL script that creates the necessary tables (i.e. posts and annotations) and the data. To simplify the process of importing data, we used the table export wizard to export the SQL table data into csv files using custom SQL as the MySQL Workbench Table Export Wizard doesn't export all of the data properly.

## Step 2.5: Preliminary EDA
We are doing a preliminary EDA in order to understand how we should clean the data and the kind of data that we are dealing with.

## Step 3: Cleaning the data / Pre-processing
```{r}
# Creates dataset column to merge posts and annotations csv files together
wow_posts_df$dataset <- "WoW"
lol_posts_df$dataset <- "LoL"
wow_annotations_df$dataset <- "WoW"
lol_annotations_df$dataset <- "LoL"

posts_df <- rbind(wow_posts_df, lol_posts_df)
annotations_df <- rbind(lol_annotations_df, wow_annotations_df)
```
Since wow_posts_df and lol_posts_df have the same structure, we merged the posts and annotation data frames together to simplify pre-processing (this avoids repeating code). However, we will need to analyse the datasets separately for EDA purposes so we created a "dataset" feature to counteract this.

```{r}
posts_df$id <- paste(posts_df$dataset, posts_df$topic_id, posts_df$post_number, sep="_")
annotations_df$id <- paste(annotations_df$dataset, annotations_df$topic_id, annotations_df$post_number, sep="_")
```
To simplify the merging of data frames, we will create an ID column so that a left join can be performed on a single column. This mitigates the issues of duplicate topic ids and post numbers as the post numbers are only unique according to the topic id. 

```{r}
merged_df <- left_join(posts_df, annotations_df, by = "id", keep=TRUE)
merged_df$is_bullying <- as.integer(!is.na(merged_df["id.y"]))
drop <- c('topic_id.y', 'post_number.y', 'dataset.y', 'id.y', 'offender', 'victim')
merged_df <- merged_df[, !(names(merged_df) %in% drop)]

# Removes the ".x" characters from the remaining annotations columns
colnames(merged_df) = sub(".x", "", colnames(merged_df))

# Create bullying_severity column
names(merged_df)[names(merged_df) == "annotator"] <- "bullying_severity"
merged_df["bullying_severity"][is.na(merged_df["bullying_severity"])] <- 0
posts_df <- merged_df %>% group_by(id) %>% slice(which.max(bullying_severity))
```
This code performs a left join to merge the dataframes together. Most of the columns from the annotations dataframe are useless for training an NLP classifier so we will be removing those columns. Since there are duplicate columns on each side, we will be dropping "y" columns. 

We also created a bullying_severity column as we found that some posts have been annotated as bullying by multiple annotators which could make this a useful feature for model building.

```{r}
remove_html <- function(html_msg, isHtml) {
  if(isHtml) {
    # Remove backslashes when dealing with LoL forum data
    html_msg <- gsub("\\\\", '', html_msg)
    # Get XML nodes
    msg <- xml2::read_html(html_msg)
    # Get the block quotes and quotes (blockquotes for WoW, .quote for LoL)
    blockquotes <- msg %>% html_nodes("blockquote")
    quotes <- msg %>% html_nodes(".quote")
    
    # Remove quote elements for LoL and WoW datasets
    xml_remove(blockquotes)
    xml_remove(quotes)
    msg <- html_text(msg)
    return(msg)
  }
  return(html_msg)
}
```
The "html_message" column has messages that have HTML and do not contain HTML at all. In order to handle this, we will be creating a "is_html" column that uses a regular expression to detect HTML in order to prevent errors with RVest. The "tm" package does not handle removing HTML content and we cannot simply use a regular expression to remove HTML as the data originates from gaming forums where "<blockquote>" elements are frequently used. If we used a regular expression then the content inside the blockquotes would still remain.

To remove the content of the blockquotes, we used RVest to acquire the blockquote element contents as well as any <div> elements with ".quote" and then we use xml_remove() to remove the blockquote element nodes. We then convert the RVest object back into a string.

```{r}
# Regex for detecting HTML
detect_html_regex <- "<.*?>"
# Create is_html column
posts_df$is_html <- str_detect(posts_df$html_message, detect_html_regex)
# Apply remove_html function to html_message
posts_df$html_message <- mapply(remove_html, posts_df$html_message, posts_df$is_html)
posts_df <- posts_df[, !(names(posts_df) %in% 'is_html')]

# Converts any regex passed into the transformer into a space character
toSpaceTransformer <- content_transformer(function (x, pattern) gsub(pattern, "", x))
posts_corpus <- Corpus(VectorSource(posts_df$html_message))
posts_corpus <- posts_corpus %>% 
                tm_map(content_transformer(tolower)) %>%
                tm_map(toSpaceTransformer, "http\\S+\\s*") %>%
                tm_map(removeNumbers) %>%
                tm_map(removeWords, stopwords("english")) %>%
                tm_map(removePunctuation) %>%
                tm_map(stemDocument) %>%
                tm_map(stripWhitespace)
posts_df$html_message <- data.frame(text=sapply(posts_corpus, identity), stringsAsFactors = F)$text
```
This code removes useless characters, stopwords, punctuation and it uses stemming to improve model performance. Certain steps of the pre-processing could be tweaked to improve model performance (e.g. number of stopwords being omitted) as the pre-processing could end up being too rigorous. 

We removed the HTML characters first in order to prevent interference when removing punctuation or whitespace.

```{r}
posts_df$word_counts <- str_count(posts_df$html_message, "\\S+")
```
This code gets the word counts for the html messages which can be used for analysing word counts in the EDA. We may also use the word counts to filter messages with word counts that are too low.

```{r}
posts_df <- posts_df %>% na_if("") %>% na.omit
```
This code removes NaN rows from posts_df which can become a problem after pre-processing if there were too many stop words in the original messages.

```{r}
write.csv(posts_df, file="Data/clean_posts.csv")
```
This code exports the clean posts to a csv file to be analysed separately. This also comes in handy in order to save time when performing EDAs as pre-processing can take time (especially on slow computers).

```{r}
corpus = VCorpus(VectorSource(posts_df$html_message))
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
posts_data = as.data.frame(as.matrix(dtm))
posts_data$is_bullying = as.factor(posts_df$is_bullying)
```
We create a document term matrix from the html messages and we remove sparse terms using removeSparseTerms. We then assign a "is_bullying" column for model building.

```{r}
ggplot(data=posts_data, aes(x=is_bullying)) + geom_bar()
```
As we can see, the data is heavily imbalanced where there isn't many bullying cases. This will result in the classifier being trained to where it is more accurate at classifying non-bullying cases rather than bullying cases. We will use undersampling because we have plenty of non-bullying data but not enough data for bullying cases (this means we can afford to reduce how much data we are dealing with).

```{r}
is_bullying = which(posts_data$is_bullying == 1)
not_bullying = which(posts_data$is_bullying == 0)
nsamp = min(length(is_bullying), length(not_bullying))
sample_bullying = sample(is_bullying, nsamp)
sample_not_bullying = sample(not_bullying, nsamp)
posts_data_balanced = posts_data[c(sample_bullying, sample_not_bullying),]

ggplot(data=posts_data_balanced, aes(x=is_bullying)) + geom_bar()
```
This creates a sample of the bullying data for balancing purposes. However, this comes at the expense of having much less data to work with.

```{r}
set.seed(42)
part <- sample(2, nrow(posts_data), replace=TRUE, prob=c(0.6, 0.4))
train <- posts_data[part == 1, ]
test <- posts_data[part == 2, ]
```
We split the data using a 60:40 split.

```{r}
set.seed(42)
part <- sample(2, nrow(posts_data_balanced), replace=TRUE, prob=c(0.6, 0.4))
train_balanced <- posts_data_balanced[part == 1, ]
test_balanced <- posts_data_balanced[part == 2, ]
```
We split the data using a 60:40 split. This is for the balanced data.

```{r}
write.csv(posts_data_balanced, file="Data/clean_posts_dtm_balanced_sample.csv")
write.csv(train_balanced, file="Data/train_balanced.csv")
write.csv(test_balanced, file="Data/test_balanced.csv")
write.csv(train, file="Data/train.csv")
write.csv(test, file="Data/test.csv")
write.csv(posts_data, file="Data/clean_posts_dtm.csv")
```
We export the training and test data to make model building easier.

## Step 4: EDA

## Step 5: Feature selection

## Step 6: Predictive modelling

### Initial setup
```{r}
train_balanced$is_bullying = as.factor(train_balanced$is_bullying)
test_balanced$is_bullying = as.factor(test_balanced$is_bullying)
train_control = trainControl(method = "cv", number = 5)
```

### SVM
```{r}
set.seed(42)

tic()

svm_model = caret::train(is_bullying~., data=train_balanced , method =  "svmLinear" , trControl = train_control)

svm_toc <- toc(quiet=T)

svm_time_taken <- svm_toc$toc - svm_toc$tic
svm_pred_y = predict(svm_model, test_balanced)
```

### MLP
```{r}
set.seed(42)
tic()

mlp_model = caret::train(is_bullying~., data=train_balanced , method =  "mlp" , trControl = train_control)
mlp_toc <- toc(quiet=T)

mlp_time_taken <- mlp_toc$toc - mlp_toc$tic
mlp_pred_y = predict(mlp_model, test_balanced)
```

### Random Forest
```{r}
set.seed(42)

tic()

rf_model = caret::train(is_bullying~., data=train_balanced , method =  "rf" , trControl = train_control)

rf_toc <- toc(quiet=T)

rf_time_taken <- rf_toc$toc - rf_toc$tic
rf_pred_y = predict(rf_model, test_balanced)
```

## Step 7: Evaluation
### Confusion matrices
```{r}
svm_confusion_matrix <- caret::confusionMatrix(data=svm_pred_y, reference=test_balanced$is_bullying, mode="everything")
mlp_confusion_matrix <- caret::confusionMatrix(data=mlp_pred_y, reference=test_balanced$is_bullying, mode="everything")
rf_confusion_matrix <- caret::confusionMatrix(data=rf_pred_y, reference=test_balanced$is_bullying, mode="everything")
```
Here we create confusion matrices to get values such as F1 score, precision and recalls. When we use "mode="everything" ", we get additional values such as F1 Score for a better overview of the model performance.

```{r}
svm_confusion_matrix
```

```{r}
mlp_confusion_matrix
```

```{r}
rf_confusion_matrix
```

### ROC Curves
```{r}
converted_pred_y_svm <- as.numeric(levels(svm_pred_y))[svm_pred_y]
converted_pred_y_mlp <- as.numeric(levels(mlp_pred_y))[mlp_pred_y]
converted_pred_y_rf <- as.numeric(levels(rf_pred_y))[rf_pred_y]

par(pty="s")
svm_roc <- roc(test_balanced$is_bullying~converted_pred_y_svm, plot=TRUE, print.auc=TRUE, col="red", lwd=4, legacy.axes=TRUE, main="ROC Curves")
mlp_roc <- roc(test_balanced$is_bullying~converted_pred_y_mlp, plot=TRUE, print.auc=TRUE, print.auc.y=0.4, col="blue", lwd=4, legacy.axes=TRUE, add=TRUE)
rf_roc <- roc(test_balanced$is_bullying, converted_pred_y_rf, plot=TRUE, print.auc=TRUE, print.auc.y=0.6, col="green", lwd=4, legacy.axes=TRUE, add=TRUE)

legend("bottomright", legend=c("SVM", "MLP", "RF"), col=c("red", "blue", "green"), lwd=4)
```
This code creates ROC curves for each model with different colours. We then print the AUC values for each curve.

### Table of metrics
#### Calculating metrics
For each model, we will be calculating the evaluation metrics we will be using (time taken, precision, sensitivity, f1 score, AUC) to create a table of metrics which can be used to evaluate each model. We are acquiring the time taken to train each model to see how practical the models would be in a real world project.

```{r}
svm_precision <- precision(svm_pred_y, test_balanced$is_bullying)
svm_sensitivity <- sensitivity(svm_pred_y, test_balanced$is_bullying)
svm_f1_score <- F_meas(svm_pred_y, test_balanced$is_bullying)
svm_auc <- auc(svm_roc)
```

```{r}
mlp_precision <- precision(mlp_pred_y, test_balanced$is_bullying)
mlp_sensitivity <- sensitivity(mlp_pred_y, test_balanced$is_bullying)
mlp_f1_score <- F_meas(mlp_pred_y, test_balanced$is_bullying)
mlp_auc <- auc(mlp_roc)
```

```{r}
rf_precision <- precision(rf_pred_y, test_balanced$is_bullying)
rf_sensitivity <- sensitivity(rf_pred_y, test_balanced$is_bullying)
rf_f1_score <- F_meas(rf_pred_y, test_balanced$is_bullying)
rf_auc <- auc(rf_roc)
```

#### Table
```{r}
Model_Name <- c("SVM", "MLP", "RF")
Precision <- c(svm_precision, mlp_precision, rf_precision)
Sensitivity <- c(svm_sensitivity, mlp_sensitivity, rf_sensitivity)
F1_Score <- c(svm_f1_score, mlp_f1_score, rf_f1_score)
AUC <- c(svm_auc, mlp_auc, rf_auc)
Time_to_Train_secs <- c(svm_time_taken, mlp_time_taken, rf_time_taken)

results <- data.frame(Model_Name, Precision, Sensitivity, F1_Score, AUC, Time_to_Train_secs)
results
```

### Output evaluation results
```{r}
write.csv(results, "Data/results.csv")
```
We output the table results to a csv file to make it easy to share results with other group members.

## Step 8: Hyperparameter tuning

# Individual contributions

# References
Bretschneider, Uwe and Peters, Ralf, "DETECTING CYBERBULLYING IN ONLINE COMMUNITIES" (2016). Research Papers. Paper 61. http://aisel.aisnet.org/ecis2016_rp/61