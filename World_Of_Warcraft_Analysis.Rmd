---
title: "World of Warcraft Analysis"
output: 
  R_markdown:
   toc: true
   toc_float: true
---

# Pro Data Scientists - Applied Predictive Modelling Project

### Team members

Leon Harper (21385662)

Thomas Newton (21365654)

Michal Jedruszczak (21440496)

# Initial set-up

## Libraries to use

```{r}
install.packages("dplyr")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("tidytext")
install.packages("wordcloud")
install.packages("igraph")
install.packages("ggraph")
```

```{r}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(igraph)
library(ggraph)
```

# World of Warcraft Cyberbullying Dataset analysis

## Step 1: Problem statement

World of Warcraft is a popular MMORPG (Massively multiplayer online role-playing game) video game with millions of user every month. Due to having this many players there is bound to be some cyberbullying/toxic players included in those millions of players, World of Warcraft however is especially toxic and is often ranked as one of the most toxic gaming community's today. In a survey by ADL (Anti-Defamation League) it was found 66% of adults ages 18-45 have been harassed/bullied in World of Warcraft in 2021.

The objective of this project is to create a model that will be able to detect cyberbullying/toxicity. By using the World of Warcraft dataset provided to us it will allow the model to have reference for comments deemed as bullying.

This would be a classification model that when give a comment/statement would decided whether it is bullying or not bullying, it will be able to do this by detecting certain words and phrases.

Currently most video games have an option to filter chat, however this only censors certain words/phrases. Our model will be able to detect strings of words rather than just certain ones.

ADL Survey: Hate is No Game: Harassment and Positive Social Experiences in Online Games 2021 (adl.org)

## Step 2: Importing data

```{r}
wow_posts_df <- read.csv("Data/posts_wow.csv")
wow_annotations_df <- read.csv("Data/annotations_wow.csv")
```

### Step 2.5: Preliminary EDA

```{r}
posts_wow <- read.csv("./posts_wow.csv")
annotations_wow <- read.csv("./annotations_wow.csv")
```

In our World of Warcraft posts dataset, we are given 354 rows of 5 features: topic_id, post_number, author, html_message and timestamp. For the purposes of this project, we will ignore timestamp, as it will not be used to train our models. The additional WoW annotations dataset reveals which messages were flagged as cyberbullying, from which the only useful features are the post_number and topic_id. This information has been combined into a single file -- clean_posts_balanced_sample.csv.

Posts in the main dataset are formatted using HTML, meaning that our model will either have to be trained to recognise patterns such as paragraph breaks or we will have to clean the data and transform it into something more appropriate.

Furthermore, as we are only using a single set of features (post_number and topic_id) from the annotations dataset, we may be able to add another column to the posts dataset -- a Boolean value representing whether or not a specific post contains cyberbullying. This will eliminate the need for the use of two separate datasets to develop our models.

Regarding the types of data we're given, topic IDs, authors and HTML messages are categorical, while post numbers are ordinal. In the annotations data set, all values but post number are categorical.

```{r}
posts_wow <- read.csv(file.choose())
clean_posts_balanced_sample %>% filter(dataset == "WoW") -> posts_wow
posts_wow #Selecting the World of Warcraft dataset
```

```{r}
summary(posts_wow)
```

```{r}
nrow(posts_wow)
```

There are 354 data points in this sample.

```{r}
posts_wow %>% select("topic_id") -> wow_topics #gets all unique wow_topics from the dataset
nrow(unique(wow_topics))
```

This data set has a total of 20 different topics.

```{r}
posts_wow %>% filter(is_bullying == 1) -> bullying_wow
bullying_wow
```

```{r}
100 * count(bullying_wow)/count(posts_wow)#percentage of posts marked as cyberbullying
```

For this data set 43.8% of the posts are labeled as bullying.

## Step 3: Cleaning the data

## Step 4: EDA

```{r}
clean_posts_balanced_sample <- read.csv(file.choose())
```

```{r}
clean_posts_balanced_sample %>% filter(dataset == "WoW") -> posts_wow
#Selecting the World of Warcraft dataset
```

```{r}
wow_tibble <- tibble(txt = posts_wow$html_message)
wow_tibble #transforming the HTML messages into a tibble for an easier workflow
```

```{r}
wow_tibble <- wow_tibble%>% 
    mutate(linenumber = row_number()) %>%
 unnest_tokens(word, txt) %>% anti_join(stop_words)
wow_tibble #splitting tibble by words and removing stop words
```

```{r}
wow_counts <- wow_tibble %>% count(word, sort=TRUE)
wow_counts #sorting and counting the remaining words
```

```{r}
wordcloud(wow_counts$word, wow_counts$n, 
          min.freq=25, random.order=FALSE, colors=brewer.pal(8, "Dark2"))
  #creating word cloud
```

```{r}
wow_bigrams <- tibble(txt = posts_wow$html_message) %>% 
  unnest_tokens(bigram, txt, token = "ngrams", n = 2)
wow_bigrams #split original tibble into two-word bigrams
```

```{r}
wow_bigrams <- wow_bigrams %>%
      separate(bigram, c("word1", "word2"), sep = " ") 
wow_bigrams #separating them out for easier cleaning
```

```{r}
wow_bigrams <- wow_bigrams %>%
      filter(!word1 %in% stop_words$word) %>%
      filter(!word2 %in% stop_words$word)
wow_bigrams #filtering out unwanted words
```

```{r}
wow_bigrams <- wow_bigrams %>%
            filter(!is.na(word1)) %>% 
            filter(!is.na(word2))
wow_bigrams #removing null values
```

```{r}
wow_bigrams <- wow_bigrams %>%
            unite(bigram, word1, word2, sep=" ")
wow_bigrams #joining the words back together
```

```{r}
wow_bigram_counts <- wow_bigrams %>% count(bigram, sort=TRUE)
wow_bigram_counts #counting and sorting bigrams
```

```{r}
wow_bigram_counts %>% 
  filter(str_detect(wow_bigram_counts$bigram,"[0-9]", negate = TRUE)) -> wow_bigram_counts
wow_bigram_counts #removing any bigrams with numbers
```

```{r}
wow_filtered_bigrams <- wow_bigram_counts %>%
                  filter(n >= 4)
wow_filtered_bigrams #sorting remaining bigrams with a frequency of 4 or more
```

```{r}
wow_separated_bigrams <- wow_filtered_bigrams %>% 
  select("bigram") %>%
  separate(bigram, c("word1", "word2"), sep = " ") 
wow_separated_bigrams #separating bigrams again, preparing for graphical representation
```

```{r}
wow_bigram_graph <- wow_separated_bigrams %>%
                  graph_from_data_frame()
wow_bigram_graph #creating bigram graph
```

```{r}
ggraph(wow_bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```

## Step 5: Feature selection

## Step 6: Predictive modelling

## Step 7: Evaluation

## Step 8: Hyperparameter tuning

# Individual contributions

Michal Jedruszczak - In this project I was responsible for the preliminary EDA and the final EDA. I also created the contents section and made sure that all of the references were in MMU Harvard format.

# References

Bretschneider, U. and Peters, R. "Detecting Cyberbullying in Online Communities" (2016). *Research Papers*. Paper 61. <http://aisel.aisnet.org/ecis2016_rp/61>
